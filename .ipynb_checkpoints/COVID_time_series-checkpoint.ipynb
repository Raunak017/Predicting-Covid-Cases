{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5fb133",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb23ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext watermark\n",
    "%watermark -v -p numpy,pandas,torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from torch import nn, optim\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n",
    "\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 10\n",
    "register_matplotlib_converters()\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f17a59",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "df = pd.read_csv ('./time_series_covid19_confirmed_global.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1dcbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, 4:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases = df.sum(axis=0)\n",
    "daily_cases.index = pd.to_datetime(daily_cases.index)\n",
    "daily_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ca722",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daily_cases)\n",
    "plt.title(\"Cumulative daily cases\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases = daily_cases.diff().fillna(daily_cases[0]).astype(np.int64)\n",
    "daily_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daily_cases)\n",
    "plt.title(\"Daily cases\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68ca2f2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ae79d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 260 days for testing and rest for training\n",
    "test_data_size = 260\n",
    "\n",
    "train_data = daily_cases[:-test_data_size]\n",
    "test_data = daily_cases[-test_data_size:]\n",
    "\n",
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler = scaler.fit(np.expand_dims(train_data, axis=1))\n",
    "\n",
    "train_data = scaler.transform(np.expand_dims(train_data, axis=1))\n",
    "\n",
    "test_data = scaler.transform(np.expand_dims(test_data, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef91838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 5\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada61779",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d56bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2686293",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b3517",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073634f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoronaVirusPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n",
    "        super(CoronaVirusPredictor, self).__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "        self.seq_len = seq_len\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "          input_size=n_features,\n",
    "          hidden_size=n_hidden,\n",
    "          num_layers=n_layers,\n",
    "          dropout=0.5\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n",
    "\n",
    "    def reset_hidden_state(self):\n",
    "        self.hidden = (\n",
    "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n",
    "            torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n",
    "        )\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "          sequences.view(len(sequences), self.seq_len, -1),\n",
    "          self.hidden\n",
    "        )\n",
    "        last_time_step = \\\n",
    "          lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n",
    "        y_pred = self.linear(last_time_step)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f67cc",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8efde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, test_data=None, test_labels=None):\n",
    "    loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    num_epochs = 60\n",
    "    \n",
    "    train_hist = np.zeros(num_epochs)\n",
    "    test_hist = np.zeros(num_epochs)\n",
    "    \n",
    "    for t in range(num_epochs):\n",
    "        model.reset_hidden_state()\n",
    "        y_pred = model(X_train)\n",
    "        loss = loss_fn(y_pred.float(), y_train)\n",
    "        \n",
    "        if test_data is not None:\n",
    "            with torch.no_grad():\n",
    "                y_test_pred = model(X_test)\n",
    "                test_loss = loss_fn(y_test_pred.float(), y_test)\n",
    "            test_hist[t] = test_loss.item()\n",
    "            \n",
    "            if t % 10 == 0:\n",
    "                print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n",
    "                \n",
    "        elif t % 10 == 0:\n",
    "            print(f'Epoch {t} train loss: {loss.item()}')\n",
    "            \n",
    "        train_hist[t] = loss.item()\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "    return model.eval(), train_hist, test_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f764fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoronaVirusPredictor(\n",
    "  n_features=1, \n",
    "  n_hidden=512, \n",
    "  seq_len=seq_length, \n",
    "  n_layers=2\n",
    ")\n",
    "model, train_hist, test_hist = train_model(\n",
    "  model, \n",
    "  X_train, \n",
    "  y_train, \n",
    "  X_test, \n",
    "  y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463d1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_hist, label=\"Training loss\")\n",
    "plt.plot(test_hist, label=\"Test loss\")\n",
    "plt.ylim((0, 100))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1c691",
   "metadata": {},
   "source": [
    "# Predicting Daily Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e455fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_seq = X_test[:1]\n",
    "    preds = []\n",
    "    \n",
    "    for _ in range(len(X_test)):\n",
    "        y_test_pred = model(test_seq)\n",
    "        pred = torch.flatten(y_test_pred).item()\n",
    "        preds.append(pred)\n",
    "        new_seq = test_seq.numpy().flatten()\n",
    "        new_seq = np.append(new_seq, [pred])\n",
    "        new_seq = new_seq[1:]\n",
    "        test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dc7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cases = scaler.inverse_transform(\n",
    "    np.expand_dims(y_test.flatten().numpy(), axis=0)\n",
    ").flatten()\n",
    "\n",
    "predicted_cases = scaler.inverse_transform(\n",
    "  np.expand_dims(preds, axis=0)\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f006e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "  daily_cases.index[:len(train_data)], \n",
    "  scaler.inverse_transform(train_data).flatten(),\n",
    "  label='Historical Daily Cases'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n",
    "  true_cases,\n",
    "  label='Real Daily Cases'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n",
    "  predicted_cases, \n",
    "  label='Predicted Daily Cases'\n",
    ")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d27639",
   "metadata": {},
   "source": [
    "# Using all data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler = scaler.fit(np.expand_dims(daily_cases, axis=1))\n",
    "\n",
    "all_data = scaler.transform(np.expand_dims(daily_cases, axis=1))\n",
    "\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = create_sequences(all_data, seq_length)\n",
    "\n",
    "X_all = torch.from_numpy(X_all).float()\n",
    "y_all = torch.from_numpy(y_all).float()\n",
    "\n",
    "model = CoronaVirusPredictor(\n",
    "  n_features=1, \n",
    "  n_hidden=512, \n",
    "  seq_len=seq_length, \n",
    "  n_layers=2\n",
    ")\n",
    "model, train_hist, _ = train_model(model, X_all, y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115f639",
   "metadata": {},
   "source": [
    "# Predicting Future Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08991671",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_TO_PREDICT = 12\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_seq = X_all[:1]\n",
    "    preds = []\n",
    "    \n",
    "    for _ in range(DAYS_TO_PREDICT):\n",
    "        y_test_pred = model(test_seq)\n",
    "        pred = torch.flatten(y_test_pred).item()\n",
    "        preds.append(pred)\n",
    "        new_seq = test_seq.numpy().flatten()\n",
    "        new_seq = np.append(new_seq, [pred])\n",
    "        new_seq = new_seq[1:]\n",
    "        test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25164587",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cases = scaler.inverse_transform(\n",
    "  np.expand_dims(preds, axis=0)\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aed60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_cases.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_index = pd.date_range(\n",
    "  start=daily_cases.index[-1],\n",
    "  periods=DAYS_TO_PREDICT + 1,\n",
    "  closed='right'\n",
    ")\n",
    "\n",
    "predicted_cases = pd.Series(\n",
    "  data=predicted_cases,\n",
    "  index=predicted_index\n",
    ")\n",
    "\n",
    "plt.plot(predicted_cases, label='Predicted Daily Cases')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daily_cases, label='Historical Daily Cases')\n",
    "plt.plot(predicted_cases, label='Predicted Daily Cases')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daily_cases[970:], label='Daily Cases (Last 2 Months)')\n",
    "plt.plot(predicted_cases, label='Predicted Daily Cases')\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
